# ğŸ“˜ README â€“ Etapa 3: Analiza È™i PregÄƒtirea Setului de Date pentru ReÈ›ele Neuronale

**Disciplina:** ReÈ›ele Neuronale  
**InstituÈ›ie:** POLITEHNICA BucureÈ™ti â€“ FIIR  
**Student:** Ilie Marian-Ionut  
**Data:** 20.11.2025  

---

## Introducere

Acest document descrie activitÄƒÈ›ile realizate Ã®n **Etapa 3**, Ã®n care se analizeazÄƒ È™i se preproceseazÄƒ setul de date necesar proiectului â€ReÈ›ele Neuronale". Scopul etapei este pregÄƒtirea corectÄƒ a datelor pentru instruirea modelului RN, respectÃ¢nd bunele practici privind calitatea, consistenÈ›a È™i reproductibilitatea datelor.

---

##  1. Structura Repository-ului Github (versiunea Etapei 3)

```
SMARTPARK-UPB/
â”œâ”€â”€ README.md
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ datasets/          # grafice distributie, descriere tehnica
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # resurse: fundaluri parcare, imagini masini (png.)
â”‚   â”œâ”€â”€ processed/         # date generate (crop-uri 64x64)
â”‚   â”œâ”€â”€ train/             # set de instruire (organizat pe clase)
â”‚   â”œâ”€â”€ validation/        # set de validare
â”‚   â””â”€â”€ test/              # set de testare
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing/     # scripturi: split_dataset.py, visualize_stats.py
â”‚   â”œâ”€â”€ data_acquisition/  # scripturi: config_backgrounds.py, generate_synthetic_data.py
â”‚   â””â”€â”€ neural_network/    # implementarea RN (train_cnn.py) 
â”œâ”€â”€ config/                # synthetic_spots.json (coordonate locuri)
â””â”€â”€ requirements.txt       # dependenÈ›e Python (torch, cv2, etc.)
```

---

##  2. Descrierea Setului de Date

### 2.1 Sursa datelor

* **Origine:** Date Sintetice generate programatic. S-au utilizat 4 layout-uri de parcare (schiÈ›e/poze reale) È™i 4 asset-uri de autovehicule (fotografiate top-down È™i decupate).
* **Modul de achiziÈ›ie:** â˜‘ Generare programaticÄƒ (Script Python cu OpenCV).
* **Perioada / condiÈ›iile colectÄƒrii:** Noiembrie 2025. S-au simulat algoritmic 3 condiÈ›ii de iluminare: DimineaÈ›a (neutru), PrÃ¢nz (contrast ridicat), Seara (luminozitate scÄƒzutÄƒ, tentÄƒ albastrÄƒ).

### 2.2 Caracteristicile dataset-ului

* **NumÄƒr total de observaÈ›ii:** 3600 imagini generate.
* **NumÄƒr de caracteristici (features):** Input: Matrice de pixeli (64x64x3).
* **Tipuri de date:** â˜‘ Imagini (Numerice - Tensori).
* **Format fiÈ™iere:** â˜‘ JPG (Imagini), JSON (Metadate/Configurare).

### 2.3 Descrierea fiecÄƒrei caracteristici

| **CaracteristicÄƒ** |  **Tip**   |  **Unitate**  |                        **Descriere**                       | **Domeniu valori** |
|--------------------|------------|---------------|------------------------------------------------------------|--------------------|
| Pixel (R,G,B)      | Numeric    |  Intensitate  | Valoarea bruta a pixelului preluat de senzor               |   0â€“255 (uint8)    |
| Pixel Normalizat   | Numeric    |      -        | Valorea pixelului dupa standardizare (Mean=0.5, Std=0.5)   | -1.0-1.0 (float)   |
| Label(Clasa)       | Categorial |      -        | Eticheta locului de parcare (Target de predictie)          | 0: Liber, 1: Ocupa |

**FiÈ™ier recomandat:**  `data/README.md`

---

##  3. Analiza Exploratorie a Datelor (EDA) â€“ Sintetic

### 3.1 Statistici descriptive aplicate

* **Distributia claselor:** Dataset-ul este perfect echilibrat prin constructie (algorimtul a generat un numar egal de instante pentru fiecare scenariu).
* **Variatia iluminarii:** 33% Dimineata, 33% Pranz, 33% Seara.
* **DistribuÈ›ii pe caracteristici** (histograme)
* **Dimensiuni:** Toate imaginile sunt standardizate la 64x64 pixeli.

### 3.2 Analiza calitÄƒÈ›ii datelor

* **Detectarea valorilor lipsÄƒ:** Nu exista (date sintetice).
* **Consistenta:** Toate imaginile au aceeasi rezolutie si adancime de culoare (3 canale).
* **Identificarea artefactelor:** Verificarea vizuala a masinilor generate la marginea locurilor de parcare (clipping).

### 3.3 Probleme identificate si solutii

* Problema: Riscul de overfitting pe formele specifice ale celor 4 masini folosite.
  * Solutie: S-a aplicat augmentare geometrica (rotatie aleatorie, scalare 85-95%) in momentul generarii.

* Problema: Similitudine mare intre cadrele succesive.
  * Solutie: split_dataset.py foloseste random.shuffle() inainte de impartire pentru a asigura diversitatea.

---

##  4. Preprocesarea Datelor

### 4.1 CurÄƒÈ›area datelor

* **Filtrare:** Scriptul de generare elimina automat crop-urile care au dimensiuni nule sau invalide (care ies din cadru imaginii de fundal).

### 4.2 Transformarea caracteristicilor

* **Redimensionare:** Toate crop-urile sunt aduse la 64x64 pixeli.

* **Conversie Tensor:** Transformarea din matrice NumPy (H, W, C) Ã®n Tensor PyTorch (C, H, W).

* **Normalizare:** Aplicarea standardizÄƒrii: mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5] pentru a centra datele È™i a ajuta convergenÈ›a CNN-ului.

### 4.3 Structurarea seturilor de date

S-a utilizat scriptul split_dataset.py pentru a imparti datele din data/processed/ in:

* **Train(70%):** 2520 imagini (pentru atrenarea greutatilor).
* **Validation(15%):** 540 imagini (pentru monitorizarea epocilor si prevenirea overfitting).
* **Test(15%):** 540 imagini (pentru evalurea finala).

### 4.4 Salvarea rezultatelor preprocesÄƒrii

* **Structura finala pe disc:**
  * data/train/liber & data/train/ocupat
  * data/validation/liber & data/validation/ocupat
  * data/test/liber & data/test/ocupat

---

##  5. FiÈ™iere Generate Ã®n AceastÄƒ EtapÄƒ

* src/data_acquisition/generate_synthetic_data.py â€“ motorul de generare date.
* src/preprocessing/split_dataset.py â€“ utilitarul de Ã®mpÄƒrÈ›ire train/validare/test.
* src/preprocessing/visualize_stats.py â€“ generatorul de grafice.
* config/synthetic_spots.json â€“ coordonatele ROI pentru generare.
* data/processed/ â€“ repository-ul cu cele 3600 imagini brute.

---

##  6. Stare EtapÄƒ (de completat de student)

- â˜‘ StructurÄƒ repository configuratÄƒ
- â˜‘ Dataset analizat (EDA realizatÄƒ)
- â˜‘ Date preprocesate
- â˜‘ Seturi train/val/test generate
- â˜‘ DocumentaÈ›ie actualizatÄƒ Ã®n README + `data/README.md`

---
